{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4895854,"sourceType":"datasetVersion","datasetId":2839111},{"sourceId":5179248,"sourceType":"datasetVersion","datasetId":3011039}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tarfile\nimport os\ntar_bz2_file = '/kaggle/input/musiccaps-dataset/music_data.tar.bz2.0'\nextract_dir = '/kaggle/working/music_data_extracted/'\n\nos.makedirs(extract_dir,exist_ok=True)\n\nwith tarfile.open(tar_bz2_file, 'r:bz2') as tar:\n    tar.extractall(path=extract_dir) \n\nprint(f\"Extracted files to: {extract_dir}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:56:37.419844Z","iopub.execute_input":"2024-10-23T15:56:37.420421Z","iopub.status.idle":"2024-10-23T15:56:53.873822Z","shell.execute_reply.started":"2024-10-23T15:56:37.420349Z","shell.execute_reply":"2024-10-23T15:56:53.871807Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(extract_dir,exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(tar_bz2_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr:bz2\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tar:\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mtar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_dir\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted files to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/tarfile.py:2264\u001b[0m, in \u001b[0;36mTarFile.extractall\u001b[0;34m(self, path, members, numeric_owner, filter)\u001b[0m\n\u001b[1;32m   2259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misdir():\n\u001b[1;32m   2260\u001b[0m         \u001b[38;5;66;03m# For directories, delay setting attributes until later,\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m         \u001b[38;5;66;03m# since permissions can interfere with extraction and\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m         \u001b[38;5;66;03m# extracting contents can reset mtime.\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m         directories\u001b[38;5;241m.\u001b[39mappend(tarinfo)\n\u001b[0;32m-> 2264\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2265\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;66;03m# Reverse sort directories.\u001b[39;00m\n\u001b[1;32m   2268\u001b[0m directories\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m a: a\u001b[38;5;241m.\u001b[39mname, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/tarfile.py:2327\u001b[0m, in \u001b[0;36mTarFile._extract_one\u001b[0;34m(self, tarinfo, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2326\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2327\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mset_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mset_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_fatal_error(e)\n","File \u001b[0;32m/opt/conda/lib/python3.10/tarfile.py:2410\u001b[0m, in \u001b[0;36mTarFile._extract_member\u001b[0;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2407\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbg(\u001b[38;5;241m1\u001b[39m, tarinfo\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   2409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misreg():\n\u001b[0;32m-> 2410\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargetpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tarinfo\u001b[38;5;241m.\u001b[39misdir():\n\u001b[1;32m   2412\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedir(tarinfo, targetpath)\n","File \u001b[0;32m/opt/conda/lib/python3.10/tarfile.py:2463\u001b[0m, in \u001b[0;36mTarFile.makefile\u001b[0;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[1;32m   2461\u001b[0m     target\u001b[38;5;241m.\u001b[39mtruncate()\n\u001b[1;32m   2462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2463\u001b[0m     \u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mReadError\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/tarfile.py:252\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[1;32m    250\u001b[0m blocks, remainder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdivmod\u001b[39m(length, bufsize)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(blocks):\n\u001b[0;32m--> 252\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buf) \u001b[38;5;241m<\u001b[39m bufsize:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected end of data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/bz2.py:164\u001b[0m, in \u001b[0;36mBZ2File.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read up to size uncompressed bytes from the file.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mIf size is negative or omitted, read until EOF is reached.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03mReturns b'' if the file is already at EOF.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_can_read()\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[0;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n","File \u001b[0;32m/opt/conda/lib/python3.10/_compression.py:97\u001b[0m, in \u001b[0;36mDecompressReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39mneeds_input:\n\u001b[0;32m---> 97\u001b[0m         rawblock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBUFFER_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rawblock:\n\u001b[1;32m     99\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompressed file ended before the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend-of-stream marker was reached\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"/kaggle/input/musiccaps/musiccaps-public.csv\")\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T17:42:18.452227Z","iopub.execute_input":"2024-10-23T17:42:18.453078Z","iopub.status.idle":"2024-10-23T17:42:18.552656Z","shell.execute_reply.started":"2024-10-23T17:42:18.453036Z","shell.execute_reply":"2024-10-23T17:42:18.551770Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"          ytid  start_s  end_s  \\\n0  -0Gj8-vB1q4       30     40   \n1  -0SdAVK79lg       30     40   \n2  -0vPFx-wRRI       30     40   \n3  -0xzrMun0Rs       30     40   \n4  -1LrH01Ei1w       30     40   \n\n                            audioset_positive_labels  \\\n0                       /m/0140xf,/m/02cjck,/m/04rlf   \n1  /m/0155w,/m/01lyv,/m/0342h,/m/042v_gx,/m/04rlf...   \n2                                /m/025_jnm,/m/04rlf   \n3                                 /m/01g90h,/m/04rlf   \n4                                /m/02p0sh1,/m/04rlf   \n\n                                         aspect_list  \\\n0  ['low quality', 'sustained strings melody', 's...   \n1  ['guitar song', 'piano backing', 'simple percu...   \n2  ['amateur recording', 'finger snipping', 'male...   \n3  ['backing track', 'jazzy', 'digital drums', 'p...   \n4  ['rubab instrument', 'repetitive melody on dif...   \n\n                                             caption  author_id  \\\n0  The low quality recording features a ballad so...          4   \n1  This song features an electric guitar as the m...          0   \n2  a male voice is singing a melody with changing...          6   \n3  This song contains digital drums playing a sim...          6   \n4  This song features a rubber instrument being p...          0   \n\n   is_balanced_subset  is_audioset_eval  \n0               False              True  \n1               False             False  \n2               False              True  \n3               False              True  \n4               False             False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ytid</th>\n      <th>start_s</th>\n      <th>end_s</th>\n      <th>audioset_positive_labels</th>\n      <th>aspect_list</th>\n      <th>caption</th>\n      <th>author_id</th>\n      <th>is_balanced_subset</th>\n      <th>is_audioset_eval</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0Gj8-vB1q4</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/0140xf,/m/02cjck,/m/04rlf</td>\n      <td>['low quality', 'sustained strings melody', 's...</td>\n      <td>The low quality recording features a ballad so...</td>\n      <td>4</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0SdAVK79lg</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/0155w,/m/01lyv,/m/0342h,/m/042v_gx,/m/04rlf...</td>\n      <td>['guitar song', 'piano backing', 'simple percu...</td>\n      <td>This song features an electric guitar as the m...</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0vPFx-wRRI</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/025_jnm,/m/04rlf</td>\n      <td>['amateur recording', 'finger snipping', 'male...</td>\n      <td>a male voice is singing a melody with changing...</td>\n      <td>6</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0xzrMun0Rs</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/01g90h,/m/04rlf</td>\n      <td>['backing track', 'jazzy', 'digital drums', 'p...</td>\n      <td>This song contains digital drums playing a sim...</td>\n      <td>6</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1LrH01Ei1w</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/02p0sh1,/m/04rlf</td>\n      <td>['rubab instrument', 'repetitive melody on dif...</td>\n      <td>This song features a rubber instrument being p...</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"aspect_list = df['aspect_list'].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T17:42:20.653516Z","iopub.execute_input":"2024-10-23T17:42:20.654372Z","iopub.status.idle":"2024-10-23T17:42:20.658996Z","shell.execute_reply.started":"2024-10-23T17:42:20.654332Z","shell.execute_reply":"2024-10-23T17:42:20.658124Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"ytids = df['ytid'].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T17:42:21.458427Z","iopub.execute_input":"2024-10-23T17:42:21.459317Z","iopub.status.idle":"2024-10-23T17:42:21.463640Z","shell.execute_reply.started":"2024-10-23T17:42:21.459277Z","shell.execute_reply":"2024-10-23T17:42:21.462659Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\n\naspect_list = df['aspect_list'].tolist()\nytids = df['ytid'].tolist()\n\nwav_directory = '/kaggle/working/music_data_extracted/music_data'  \nwav_files = os.listdir(wav_directory)\n\nmapping = {}\n\nfor ytid, aspect in zip(ytids, aspect_list):\n    wav_filename = f\"{ytid}.wav\" \n    if wav_filename in wav_files:  \n        mapping[ytid] = {\n            'aspect': aspect,\n            'wav_file': wav_filename\n        }\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T17:42:22.327112Z","iopub.execute_input":"2024-10-23T17:42:22.327928Z","iopub.status.idle":"2024-10-23T17:42:22.456942Z","shell.execute_reply.started":"2024-10-23T17:42:22.327889Z","shell.execute_reply":"2024-10-23T17:42:22.455967Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import string\n\ncharacters = string.ascii_letters + ' ' + string.punctuation  \n\nchar_to_index = {char: index for index, char in enumerate(characters)}\n\nprint(\"Character to Index Mapping:\", char_to_index)\n\ndef encode_prompt(prompts):\n    encoded_indices = []\n    for prompt in prompts:\n        prompt_cleaned = prompt.lower()  \n        for char in prompt_cleaned:\n            if char in char_to_index: \n                encoded_indices.append(char_to_index[char])\n    return encoded_indices\n\nuser_prompt = [\"low quality!\"]\nencoded_prompt = encode_prompt(user_prompt)\n\nprint(f\"Encoded prompt for {user_prompt}: {encoded_prompt}\")\n\nprint(\"All Characters:\", characters)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T17:42:23.255346Z","iopub.execute_input":"2024-10-23T17:42:23.256111Z","iopub.status.idle":"2024-10-23T17:42:23.264339Z","shell.execute_reply.started":"2024-10-23T17:42:23.256070Z","shell.execute_reply":"2024-10-23T17:42:23.263336Z"}},"outputs":[{"name":"stdout","text":"Character to Index Mapping: {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, 'A': 26, 'B': 27, 'C': 28, 'D': 29, 'E': 30, 'F': 31, 'G': 32, 'H': 33, 'I': 34, 'J': 35, 'K': 36, 'L': 37, 'M': 38, 'N': 39, 'O': 40, 'P': 41, 'Q': 42, 'R': 43, 'S': 44, 'T': 45, 'U': 46, 'V': 47, 'W': 48, 'X': 49, 'Y': 50, 'Z': 51, ' ': 52, '!': 53, '\"': 54, '#': 55, '$': 56, '%': 57, '&': 58, \"'\": 59, '(': 60, ')': 61, '*': 62, '+': 63, ',': 64, '-': 65, '.': 66, '/': 67, ':': 68, ';': 69, '<': 70, '=': 71, '>': 72, '?': 73, '@': 74, '[': 75, '\\\\': 76, ']': 77, '^': 78, '_': 79, '`': 80, '{': 81, '|': 82, '}': 83, '~': 84}\nEncoded prompt for ['low quality!']: [11, 14, 22, 52, 16, 20, 0, 11, 8, 19, 24, 53]\nAll Characters: abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"aspects = [aspect for info in mapping.values() for aspect in info['aspect']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T17:42:25.238898Z","iopub.execute_input":"2024-10-23T17:42:25.239280Z","iopub.status.idle":"2024-10-23T17:42:25.249434Z","shell.execute_reply.started":"2024-10-23T17:42:25.239243Z","shell.execute_reply":"2024-10-23T17:42:25.248501Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"encoded_aspects = []\nfor info in mapping.values():\n    aspect = info['aspect']\n    encoded_aspect = encode_prompt([aspect])\n    encoded_aspects.append((aspect, encoded_aspect, info['wav_file']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T17:42:26.104253Z","iopub.execute_input":"2024-10-23T17:42:26.105118Z","iopub.status.idle":"2024-10-23T17:42:26.137236Z","shell.execute_reply.started":"2024-10-23T17:42:26.105076Z","shell.execute_reply":"2024-10-23T17:42:26.136374Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"for aspect, encoded_aspect, wav_file in encoded_aspects[:3]:\n    print(f\"Aspect: {aspect}, Encoded: {encoded_aspect}, .wav file: {wav_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T17:42:27.386572Z","iopub.execute_input":"2024-10-23T17:42:27.386955Z","iopub.status.idle":"2024-10-23T17:42:27.392516Z","shell.execute_reply.started":"2024-10-23T17:42:27.386919Z","shell.execute_reply":"2024-10-23T17:42:27.391542Z"}},"outputs":[{"name":"stdout","text":"Aspect: ['low quality', 'sustained strings melody', 'soft female vocal', 'mellow piano melody', 'sad', 'soulful', 'ballad'], Encoded: [75, 59, 11, 14, 22, 52, 16, 20, 0, 11, 8, 19, 24, 59, 64, 52, 59, 18, 20, 18, 19, 0, 8, 13, 4, 3, 52, 18, 19, 17, 8, 13, 6, 18, 52, 12, 4, 11, 14, 3, 24, 59, 64, 52, 59, 18, 14, 5, 19, 52, 5, 4, 12, 0, 11, 4, 52, 21, 14, 2, 0, 11, 59, 64, 52, 59, 12, 4, 11, 11, 14, 22, 52, 15, 8, 0, 13, 14, 52, 12, 4, 11, 14, 3, 24, 59, 64, 52, 59, 18, 0, 3, 59, 64, 52, 59, 18, 14, 20, 11, 5, 20, 11, 59, 64, 52, 59, 1, 0, 11, 11, 0, 3, 59, 77], .wav file: -0Gj8-vB1q4.wav\nAspect: ['brass', 'double bass', 'strings', 'instrumental', 'no voice', 'percussion'], Encoded: [75, 59, 1, 17, 0, 18, 18, 59, 64, 52, 59, 3, 14, 20, 1, 11, 4, 52, 1, 0, 18, 18, 59, 64, 52, 59, 18, 19, 17, 8, 13, 6, 18, 59, 64, 52, 59, 8, 13, 18, 19, 17, 20, 12, 4, 13, 19, 0, 11, 59, 64, 52, 59, 13, 14, 52, 21, 14, 8, 2, 4, 59, 64, 52, 59, 15, 4, 17, 2, 20, 18, 18, 8, 14, 13, 59, 77], .wav file: -5FoeegAgvU.wav\nAspect: ['folk music', 'rubab', 'male voice', 'slow tempo', 'emotional song', 'low quality audio', 'violin', 'accordion'], Encoded: [75, 59, 5, 14, 11, 10, 52, 12, 20, 18, 8, 2, 59, 64, 52, 59, 17, 20, 1, 0, 1, 59, 64, 52, 59, 12, 0, 11, 4, 52, 21, 14, 8, 2, 4, 59, 64, 52, 59, 18, 11, 14, 22, 52, 19, 4, 12, 15, 14, 59, 64, 52, 59, 4, 12, 14, 19, 8, 14, 13, 0, 11, 52, 18, 14, 13, 6, 59, 64, 52, 59, 11, 14, 22, 52, 16, 20, 0, 11, 8, 19, 24, 52, 0, 20, 3, 8, 14, 59, 64, 52, 59, 21, 8, 14, 11, 8, 13, 59, 64, 52, 59, 0, 2, 2, 14, 17, 3, 8, 14, 13, 59, 77], .wav file: -5f6hjZf9Yw.wav\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nimport librosa\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport string\n\n# Load the CSV file\ndf = pd.read_csv(\"/kaggle/input/musiccaps/musiccaps-public.csv\")\n\n# Extract aspect_list and ytids\naspect_list = df['aspect_list'].tolist()\nytids = df['ytid'].tolist()\n\n# Define the directory for WAV files\nwav_directory = '/kaggle/working/music_data_extracted/music_data'  \nwav_files = os.listdir(wav_directory)\n\n# Create a mapping of ytid to aspects and wav files\nmapping = {}\nfor ytid, aspect in zip(ytids, aspect_list):\n    wav_filename = f\"{ytid}.wav\" \n    if wav_filename in wav_files:  \n        mapping[ytid] = {\n            'aspect': aspect,\n            'wav_file': wav_filename\n        }\n\n# Character to index mapping\ncharacters = string.ascii_letters + ' ' + string.punctuation  \nchar_to_index = {char: index for index, char in enumerate(characters)}\n\n# Function to encode prompts\ndef encode_prompt(prompts):\n    encoded_indices = []\n    for prompt in prompts:\n        prompt_cleaned = prompt.lower()  \n        for char in prompt_cleaned:\n            if char in char_to_index: \n                encoded_indices.append(char_to_index[char])\n    return encoded_indices\n\n# Function to load and preprocess audio files\ndef load_and_preprocess_audio_files(wav_directory, mapping, max_length=861):\n    mel_features = []\n    encoded_labels = []\n\n    for ytid, info in mapping.items():\n        wav_filename = info['wav_file']\n        y, sr = librosa.load(os.path.join(wav_directory, wav_filename), sr=22050)\n        mel = librosa.feature.melspectrogram(y=y, sr=22050, n_mels=128)\n        mel_db = librosa.power_to_db(mel, ref=np.max)  \n        \n        # Pad or trim the mel spectrogram to fixed size\n        original_length = mel_db.shape[1]  # Get the length of the mel spectrogram\n        if original_length < max_length:\n            # Pad the mel spectrogram\n            padding_size = max_length - original_length\n            padded_mel = F.pad(torch.tensor(mel_db), (0, padding_size), mode='constant', value=0)\n        else:\n            # Trim the mel spectrogram\n            padded_mel = torch.tensor(mel_db[:, :max_length])\n\n        mel_features.append(padded_mel.unsqueeze(0))  # Add channel dimension\n        encoded_aspect = encode_prompt([info['aspect']])\n        encoded_labels.append(encoded_aspect)\n\n    return mel_features, encoded_labels\n\n# Function to pad encoded labels\ndef pad_encoded_labels(encoded_labels, max_length):\n    padded_labels = []\n    for label in encoded_labels:\n        # Pad the label with zeros if it's shorter than max_length\n        if len(label) < max_length:\n            padding_size = max_length - len(label)\n            padded_label = label + [0] * padding_size  # Use 0 as padding\n        else:\n            padded_label = label[:max_length]  # Trim if longer\n        \n        padded_labels.append(padded_label)\n    \n    return padded_labels\n\n# Load and preprocess audio files\nmel_features, encoded_labels = load_and_preprocess_audio_files(wav_directory, mapping)\n\n# Pad encoded labels\nmax_label_length = max(len(label) for label in encoded_labels)  # Find the max length of labels\npadded_encoded_labels = pad_encoded_labels(encoded_labels, max_label_length)\n\n# Define the dataset class\nclass AudioTextDataset(Dataset):\n    def __init__(self, mel_features, padded_encoded_labels):\n        self.mel_features = mel_features\n        self.padded_encoded_labels = padded_encoded_labels\n\n    def __len__(self):\n        return len(self.mel_features)\n\n    def __getitem__(self, idx):\n        mel_feature = torch.tensor(self.mel_features[idx], dtype=torch.float32)  # Already a tensor\n        encoded_label = torch.tensor(self.padded_encoded_labels[idx], dtype=torch.float32)  \n        return mel_feature, encoded_label\n\n# Create the dataset\naudio_text_dataset = AudioTextDataset(mel_features, padded_encoded_labels)\n\n# Create DataLoader\nbatch_size = 64\ndataloader = DataLoader(audio_text_dataset, batch_size=batch_size, shuffle=True)\n\n# Define the WaveGAN Generator\nclass WaveGANGenerator(nn.Module):\n    def __init__(self, latent_dim, text_embedding_dim):\n        super(WaveGANGenerator, self).__init__()\n        self.main = nn.Sequential(\n            nn.ConvTranspose1d(latent_dim + text_embedding_dim, 256, kernel_size=25, stride=4, padding=11, bias=False),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose1d(256, 128, kernel_size=25, stride=4, padding=11, bias=False),\n            nn.BatchNorm1d(128),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose1d(128, 1, kernel_size=25, stride=4, padding=11, bias=False),\n            nn.Tanh()\n        )\n\n    def forward(self, noise, text_embedding):\n        combined_input = torch.cat((noise, text_embedding), dim=1)\n        return self.main(combined_input)\n\n# Define the WaveGAN Discriminator\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T18:01:56.020024Z","iopub.execute_input":"2024-10-23T18:01:56.020402Z","iopub.status.idle":"2024-10-23T18:03:22.313001Z","shell.execute_reply.started":"2024-10-23T18:01:56.020367Z","shell.execute_reply":"2024-10-23T18:03:22.311436Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/1614744945.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  mel_feature = torch.tensor(self.mel_features[idx], dtype=torch.float32)  # Already a tensor\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 184\u001b[0m\n\u001b[1;32m    181\u001b[0m real_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(mel_features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    182\u001b[0m fake_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(mel_features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 184\u001b[0m real_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_embeddings\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass text embeddings here\u001b[39;00m\n\u001b[1;32m    185\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m criterion(real_outputs, real_labels)\n\u001b[1;32m    187\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(mel_features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), latent_dim)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Generate noise\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[32], line 158\u001b[0m, in \u001b[0;36mWaveGANDiscriminator.forward\u001b[0;34m(self, x, text_embedding)\u001b[0m\n\u001b[1;32m    155\u001b[0m text_features \u001b[38;5;241m=\u001b[39m text_features\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# Expand to [batch_size, 128, mel_length]\u001b[39;00m\n\u001b[1;32m    157\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, text_features), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Now x has shape [batch_size, 128 + 128, mel_length]\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:308\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:304\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    302\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    303\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 1, 25], expected input[64, 256, 861] to have 1 channels, but got 256 channels instead"],"ename":"RuntimeError","evalue":"Given groups=1, weight of size [128, 1, 25], expected input[64, 256, 861] to have 1 channels, but got 256 channels instead","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"class WaveGANDiscriminator(nn.Module):\n    def __init__(self, text_embedding_dim):\n        super(WaveGANDiscriminator, self).__init__()\n        self.main = nn.Sequential(\n            nn.Conv1d(129, 128, kernel_size=25, stride=4, padding=11, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv1d(128, 256, kernel_size=25, stride=4, padding=11, bias=False),\n            nn.BatchNorm1d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv1d(256, 1, kernel_size=25, stride=4, padding=11, bias=False),\n        )\n        \n        self.text_embedding_layer = nn.Linear(text_embedding_dim, 128)  \n\n    def forward(self, x, text_embedding):\n        text_features = self.text_embedding_layer(text_embedding)  # Shape: [batch_size, 128]\n        \n        # Expand text_features to match the mel spectrogram shape for concatenation\n        text_features = text_features.unsqueeze(-1)  # Shape: [batch_size, 128, 1]\n        text_features = text_features.expand(-1, -1, x.size(2))  # Expand to [batch_size, 128, mel_length]\n        \n        x = torch.cat((x, text_features), dim=1)  # Now x has shape [batch_size, 128 + 128, mel_length]\n        return self.main(x)\n\n\n# Prepare for training\nlatent_dim = 100\nnum_epochs = 100\nlearning_rate = 0.0002\n\n# Prepare the text embedding dimension\ntext_embedding_dim = len(padded_encoded_labels[0])  # Use the length of the first padded label\ngenerator = WaveGANGenerator(latent_dim, text_embedding_dim)\ndiscriminator = WaveGANDiscriminator(text_embedding_dim)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer_g = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\noptimizer_d = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n\n# Training loop\nfor epoch in range(num_epochs):\n    for mel_features, text_embeddings in dataloader:\n        # Train Discriminator\n        optimizer_d.zero_grad()\n        \n        real_labels = torch.ones(mel_features.size(0), 1)\n        fake_labels = torch.zeros(mel_features.size(0), 1)\n\n        real_outputs = discriminator(mel_features.squeeze(), text_embeddings)  # Pass text embeddings here\n        d_loss_real = criterion(real_outputs, real_labels)\n        \n        noise = torch.randn(mel_features.size(0), latent_dim).unsqueeze(2)  # Generate noise\n        fake_samples = generator(noise, text_embeddings)  # Use text embeddings\n        \n        fake_outputs = discriminator(fake_samples.detach(), text_embeddings)  # Pass text embeddings here\n        d_loss_fake = criterion(fake_outputs, fake_labels)\n        \n        d_loss = d_loss_real + d_loss_fake\n        d_loss.backward()\n        optimizer_d.step()\n\n        # Train Generator\n        optimizer_g.zero_grad()\n        \n        fake_outputs = discriminator(fake_samples, text_embeddings)  # Pass text embeddings here\n        g_loss = criterion(fake_outputs, real_labels)  # We want the generator to fool the discriminator\n        \n        g_loss.backward()\n        optimizer_g.step()\n\n    print(f'Epoch [{epoch}/{num_epochs}], d_loss: {d_loss.item()}, g_loss: {g_loss.item()}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T18:05:05.541274Z","iopub.execute_input":"2024-10-23T18:05:05.541686Z","iopub.status.idle":"2024-10-23T18:05:05.862696Z","shell.execute_reply.started":"2024-10-23T18:05:05.541647Z","shell.execute_reply":"2024-10-23T18:05:05.861350Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/1614744945.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  mel_feature = torch.tensor(self.mel_features[idx], dtype=torch.float32)  # Already a tensor\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m real_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(mel_features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     47\u001b[0m fake_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(mel_features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m real_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_embeddings\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass text embeddings here\u001b[39;00m\n\u001b[1;32m     50\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m criterion(real_outputs, real_labels)\n\u001b[1;32m     52\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(mel_features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), latent_dim)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Generate noise\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[33], line 23\u001b[0m, in \u001b[0;36mWaveGANDiscriminator.forward\u001b[0;34m(self, x, text_embedding)\u001b[0m\n\u001b[1;32m     20\u001b[0m text_features \u001b[38;5;241m=\u001b[39m text_features\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# Expand to [batch_size, 128, mel_length]\u001b[39;00m\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, text_features), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Now x has shape [batch_size, 128 + 128, mel_length]\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:308\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:304\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    302\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    303\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 129, 25], expected input[64, 256, 861] to have 129 channels, but got 256 channels instead"],"ename":"RuntimeError","evalue":"Given groups=1, weight of size [128, 129, 25], expected input[64, 256, 861] to have 129 channels, but got 256 channels instead","output_type":"error"}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}